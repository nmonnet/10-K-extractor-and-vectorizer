{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e89923-8e68-4fcd-935c-fe55f463ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "import ast\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ac80ae-b21c-441d-b0ba-d12879f90dbb",
   "metadata": {},
   "source": [
    "## Last cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877b7e40-b3a0-4f6d-b4db-3a131c8c7d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/10_K_with_paragraphs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e991fcd-a3d6-4ad6-8b81-e17b41dec61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['paragraphs'] != '[]']\n",
    "df = df[df[\"date\"]>2008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84c1274c-4587-4aa1-96e5-7daf489f9f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df['ticker'].value_counts()\n",
    "tickers_to_keep = value_counts[value_counts > 3].index\n",
    "df = df[df['ticker'].isin(tickers_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0802bd20-1b70-43c7-b308-209c6be52c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7110a919-5c6e-415d-9f06-ceede37d0f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>filingDate</th>\n",
       "      <th>url</th>\n",
       "      <th>cik</th>\n",
       "      <th>ticker</th>\n",
       "      <th>paragraphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/131860...</td>\n",
       "      <td>1318605</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>[' Item 9. Changes in and Disagreements with A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-02-07</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/131860...</td>\n",
       "      <td>1318605</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>['  \\xa0 If an emerging growth company, indica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/131860...</td>\n",
       "      <td>1318605</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>['BUSINESS Overview We design, develop, manufa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/131860...</td>\n",
       "      <td>1318605</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>['BUSINESS \\xa0 Overview We design, develop, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/131860...</td>\n",
       "      <td>1318605</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>['BUSINESS \\xa0 Overview We design, develop, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24818</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023-02-24</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/106868...</td>\n",
       "      <td>1068689</td>\n",
       "      <td>ATDS</td>\n",
       "      <td>['\\xa0 The risks described above should not be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24819</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/106868...</td>\n",
       "      <td>1068689</td>\n",
       "      <td>ATDS</td>\n",
       "      <td>['\\xa0 The risks described above should not be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24820</th>\n",
       "      <td>2021</td>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/106868...</td>\n",
       "      <td>1068689</td>\n",
       "      <td>ATDS</td>\n",
       "      <td>['Item     9. Changes in and Disagreements wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24821</th>\n",
       "      <td>2020</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/106868...</td>\n",
       "      <td>1068689</td>\n",
       "      <td>ATDS</td>\n",
       "      <td>['Item     9. Changes in and Disagreements wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24822</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/106868...</td>\n",
       "      <td>1068689</td>\n",
       "      <td>ATDS</td>\n",
       "      <td>['Item 9. Changes in and Disagreements with Ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24823 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  filingDate                                                url  \\\n",
       "0      2023  2023-01-31  https://www.sec.gov/Archives/edgar/data/131860...   \n",
       "1      2022  2022-02-07  https://www.sec.gov/Archives/edgar/data/131860...   \n",
       "2      2021  2021-02-08  https://www.sec.gov/Archives/edgar/data/131860...   \n",
       "3      2020  2020-02-13  https://www.sec.gov/Archives/edgar/data/131860...   \n",
       "4      2019  2019-02-19  https://www.sec.gov/Archives/edgar/data/131860...   \n",
       "...     ...         ...                                                ...   \n",
       "24818  2023  2023-02-24  https://www.sec.gov/Archives/edgar/data/106868...   \n",
       "24819  2022  2022-03-31  https://www.sec.gov/Archives/edgar/data/106868...   \n",
       "24820  2021  2021-03-23  https://www.sec.gov/Archives/edgar/data/106868...   \n",
       "24821  2020  2020-04-17  https://www.sec.gov/Archives/edgar/data/106868...   \n",
       "24822  2019  2019-04-12  https://www.sec.gov/Archives/edgar/data/106868...   \n",
       "\n",
       "           cik ticker                                         paragraphs  \n",
       "0      1318605   TSLA  [' Item 9. Changes in and Disagreements with A...  \n",
       "1      1318605   TSLA  ['  \\xa0 If an emerging growth company, indica...  \n",
       "2      1318605   TSLA  ['BUSINESS Overview We design, develop, manufa...  \n",
       "3      1318605   TSLA  ['BUSINESS \\xa0 Overview We design, develop, m...  \n",
       "4      1318605   TSLA  ['BUSINESS \\xa0 Overview We design, develop, m...  \n",
       "...        ...    ...                                                ...  \n",
       "24818  1068689   ATDS  ['\\xa0 The risks described above should not be...  \n",
       "24819  1068689   ATDS  ['\\xa0 The risks described above should not be...  \n",
       "24820  1068689   ATDS  ['Item     9. Changes in and Disagreements wit...  \n",
       "24821  1068689   ATDS  ['Item     9. Changes in and Disagreements wit...  \n",
       "24822  1068689   ATDS  ['Item 9. Changes in and Disagreements with Ac...  \n",
       "\n",
       "[24823 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d7810d1-e891-4e9c-8402-5af7d7283a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/10_K_with_relevant_paragraphs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3627dd-d785-4030-b4da-6381293c5f13",
   "metadata": {},
   "source": [
    "## Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cef3e1d-0a51-4e8a-a441-e84c17dfec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, num_parts, base_filename):\n",
    "    # Calculate the number of rows in each part\n",
    "    rows_per_part = int(np.ceil(len(df) / num_parts))\n",
    "    \n",
    "    for i in range(num_parts):\n",
    "        start_row = i * rows_per_part\n",
    "        end_row = min((i + 1) * rows_per_part, len(df))\n",
    "        df_part = df.iloc[start_row:end_row]\n",
    "        \n",
    "        # Generate filename for each part\n",
    "        filename = f\"{base_filename}_part_{i+1}.csv\"\n",
    "        df_part.to_csv(filename, index=False)\n",
    "        print(f\"Saved {filename}\")\n",
    "\n",
    "# Split the dataframe into 20 parts\n",
    "split_dataframe(df, num_parts=20, base_filename='data/10_K_with_relevant_paragraphs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95ba6a-9327-4106-94ae-6e727c9787e2",
   "metadata": {},
   "source": [
    "## Import model and build function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4ad21-a926-4f37-aa48-08f5199f16a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the FinBERT model and tokenizer from Hugging Face\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "model = BertModel.from_pretrained('yiyanghkust/finbert-tone')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d6ba7f4-bc8f-460e-aa1b-901f74b710aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _10K_to_vector(paragraphs):\n",
    "    # Tokenize the paragraphs\n",
    "    inputs = tokenizer(paragraphs, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    # Generate embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = np.array(outputs.last_hidden_state.mean(dim=1)) # Pooling method to get a single vector per paragraph\n",
    "        norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "        #print(norms)\n",
    "        #print(norms.shape)\n",
    "        normalized_embd = embeddings / norms\n",
    "    \n",
    "        #print(normalized_embd)\n",
    "        #print(normalized_embd.shape)\n",
    "        \n",
    "        # Step 2: Compute the average of the normalized vectors\n",
    "        embd_vector = np.mean(normalized_embd, axis=0)\n",
    "    \n",
    "    \n",
    "    #print(embd_vector)\n",
    "    #print(embd_vector.shape)\n",
    "    return embd_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532d4b1c-8d07-424f-9392-6d6c5de09ac3",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7e384cd-0265-4be9-a951-4104f4936814",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/10_K_with_relevant_paragraphs.csv_part_11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91e6b9e6-f1b4-45e5-ada8-6812e63e6309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 10_Ks: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1242/1242 [23:42:26<00:00, 68.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE !\n"
     ]
    }
   ],
   "source": [
    "# Use tqdm to create a progress bar\n",
    "for i in tqdm(range(len(df)), desc=\"Processing 10_Ks\"):\n",
    "    df.at[i, \"vector\"] = str(_10K_to_vector(ast.literal_eval(df.at[i, \"paragraphs\"])).tolist())\n",
    "    df.at[i, \"paragraphs\"]=None\n",
    "    \n",
    "    \n",
    "    # Save the DataFrame every 1000 steps\n",
    "    if (i + 1) % 50 == 0:\n",
    "        df.to_csv(\"data/10_K_with_vector_11.csv\", index=False)\n",
    "        \n",
    "\n",
    "# Optionally, save the final DataFrame after the loop completes\n",
    "df.to_csv(\"data/10_K_with_vector_11.csv\", index=False)\n",
    "print(\"DONE !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a711cbd-2c51-41f6-8fd1-73ba9ae2459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/10_K_with_relevant_paragraphs.csv_part_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "710a93e0-aef1-4048-ba62-124d23bd3ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 10_Ks: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1242/1242 [23:17:35<00:00, 67.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE !\n"
     ]
    }
   ],
   "source": [
    "# Use tqdm to create a progress bar\n",
    "for i in tqdm(range(len(df)), desc=\"Processing 10_Ks\"):\n",
    "    df.at[i, \"vector\"] = str(_10K_to_vector(ast.literal_eval(df.at[i, \"paragraphs\"])).tolist())\n",
    "    df.at[i, \"paragraphs\"]=None\n",
    "    \n",
    "    \n",
    "    # Save the DataFrame every 1000 steps\n",
    "    if (i + 1) % 50 == 0:\n",
    "        df.to_csv(\"data/10_K_with_vector_12.csv\", index=False)\n",
    "        \n",
    "\n",
    "# Optionally, save the final DataFrame after the loop completes\n",
    "df.to_csv(\"data/10_K_with_vector_12.csv\", index=False)\n",
    "print(\"DONE !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "710441fc-2baa-4481-81c2-c591ad34f181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/10_K_with_relevant_paragraphs.csv_part_13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "920071f2-ef0c-497f-9669-2e95378231f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 10_Ks: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1242/1242 [23:24:56<00:00, 67.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE !\n"
     ]
    }
   ],
   "source": [
    "# Use tqdm to create a progress bar\n",
    "for i in tqdm(range(len(df)), desc=\"Processing 10_Ks\"):\n",
    "    df.at[i, \"vector\"] = str(_10K_to_vector(ast.literal_eval(df.at[i, \"paragraphs\"])).tolist())\n",
    "    df.at[i, \"paragraphs\"]=None\n",
    "    \n",
    "    \n",
    "    # Save the DataFrame every 1000 steps\n",
    "    if (i + 1) % 50 == 0:\n",
    "        df.to_csv(\"data/10_K_with_vector_13.csv\", index=False)\n",
    "        \n",
    "\n",
    "# Optionally, save the final DataFrame after the loop completes\n",
    "df.to_csv(\"data/10_K_with_vector_13.csv\", index=False)\n",
    "print(\"DONE !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1f4d035-f70f-47b7-aca9-81fc865adda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/10_K_with_relevant_paragraphs.csv_part_14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b48f5688-7ae9-4333-89e9-6f9c3a79f703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 10_Ks: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1242/1242 [26:30:45<00:00, 76.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE !\n"
     ]
    }
   ],
   "source": [
    "# Use tqdm to create a progress bar\n",
    "for i in tqdm(range(len(df)), desc=\"Processing 10_Ks\"):\n",
    "    df.at[i, \"vector\"] = str(_10K_to_vector(ast.literal_eval(df.at[i, \"paragraphs\"])).tolist())\n",
    "    df.at[i, \"paragraphs\"]=None\n",
    "    \n",
    "    \n",
    "    # Save the DataFrame every 1000 steps\n",
    "    if (i + 1) % 50 == 0:\n",
    "        df.to_csv(\"data/10_K_with_vector_14.csv\", index=False)\n",
    "        \n",
    "\n",
    "# Optionally, save the final DataFrame after the loop completes\n",
    "df.to_csv(\"data/10_K_with_vector_14.csv\", index=False)\n",
    "print(\"DONE !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dca69c3-a350-494f-acca-64281e84ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/10_K_with_relevant_paragraphs.csv_part_15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fb8e9b7-9701-4b9d-a10f-843fe1502f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 10_Ks: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1242/1242 [29:04:26<00:00, 84.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE !\n"
     ]
    }
   ],
   "source": [
    "# Use tqdm to create a progress bar\n",
    "for i in tqdm(range(len(df)), desc=\"Processing 10_Ks\"):\n",
    "    df.at[i, \"vector\"] = str(_10K_to_vector(ast.literal_eval(df.at[i, \"paragraphs\"])).tolist())\n",
    "    df.at[i, \"paragraphs\"]=None\n",
    "    \n",
    "    \n",
    "    # Save the DataFrame every 1000 steps\n",
    "    if (i + 1) % 50 == 0:\n",
    "        df.to_csv(\"data/10_K_with_vector_15.csv\", index=False)\n",
    "        \n",
    "\n",
    "# Optionally, save the final DataFrame after the loop completes\n",
    "df.to_csv(\"data/10_K_with_vector_15.csv\", index=False)\n",
    "print(\"DONE !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be31124-b8d6-4128-bfb6-d47fb5cb4000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the additional files to transform... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
